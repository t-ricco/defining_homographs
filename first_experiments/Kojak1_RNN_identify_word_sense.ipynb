{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kojak\n",
    "\n",
    "Classifying the meaning of homographs by their context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare stopwords, preprocess the data from source file abstracts.json\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop += ['?','!','.',',',':',';','[',']','[]','“' ]\n",
    "stop += ['.', ',', '(', ')', \"'\", '\"',\"''\",'\"\"',\"``\",'”', '“', '?', '!', '’', 'et', 'al.', 'study', \"\"]\n",
    "stop = set(stop)\n",
    "\n",
    "class MyPapers(object):\n",
    "    # a memory-friendly way to load a large corpora\n",
    "     def __init__(self, dirname):\n",
    "            self.dirname = dirname\n",
    " \n",
    "     def __iter__(self):\n",
    "        with open(self.dirname) as data_file:    \n",
    "            data = json.load(data_file)\n",
    "        # iterate through all file names in our directory\n",
    "        for paper in data:\n",
    "            sentences = sent_tokenize(paper['full_text'])\n",
    "            for sentence in sentences:\n",
    "                try:\n",
    "                    line = re.sub(r'[?\\.,!:;\\(\\)“\\[\\]]',' ',sentence)\n",
    "                    line = [word for word in line.lower().split() if word not in stop]\n",
    "                    yield line\n",
    "                except:\n",
    "                    print(\"Empty line found\")\n",
    "                    \n",
    "class MySentences(object):\n",
    "    # a memory-friendly way to load a large corpora\n",
    "     def __init__(self, dirname):\n",
    "            self.dirname = dirname\n",
    " \n",
    "     def __iter__(self):\n",
    "        with open(self.dirname) as data_file:    \n",
    "            data = json.load(data_file)\n",
    "        # iterate through all file names in our directory\n",
    "        for paper in data:\n",
    "            sentences = sent_tokenize(paper['full_text'])\n",
    "            for sentence in sentences:\n",
    "                try:\n",
    "                    line = re.sub(r'[?\\.,!:;\\(\\)“\\[\\]]',' ',sentence)\n",
    "                    yield line\n",
    "                except:\n",
    "                    print(\"Empty line found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate iterable on the data\n",
    "\n",
    "#papers is an iterable of scholarly papers, tokenized for prcessing\n",
    "papers = MyPapers('../data/train_data.json') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arguments: Finds the corresponding source sentance in the source .json file\n",
    "# that corresponds to the given tokenized word_list\n",
    "\n",
    "def find_sentence(json_file, word_list):\n",
    "    words = []\n",
    "    for w in word_list:\n",
    "        for _ in w.split('_'):\n",
    "            words.append(_)\n",
    "    for paper in json_file:\n",
    "        for sentence in sent_tokenize(paper['full_text']):\n",
    "            if all(word in sentence.lower() for word in words):\n",
    "                return sentence\n",
    "            \n",
    "#Identifies and transforms corpus (An iterator) to contain bigrams and trigrams\n",
    "\n",
    "def MyPapers_plus(papers):\n",
    "    \n",
    "    phrases = gensim.models.phrases.Phrases(sentences = papers, min_count = 5, threshold = 150)\n",
    "    bigram = gensim.models.phrases.Phraser(phrases)\n",
    "    phrases2 = gensim.models.phrases.Phrases(sentences = bigram[papers], min_count = 5, threshold = 300)\n",
    "    trigram = gensim.models.phrases.Phraser(phrases2)\n",
    "    \n",
    "    return trigram[bigram[papers]]\n",
    "\n",
    "# Takes list of word tokens as arguments\n",
    "# Returns a list of vectors whose components are the arithmetic mean of the \n",
    "# corresponding component of all of the input vectors\n",
    "\n",
    "def get_vectors(word_list):\n",
    "    vecs = []\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            vecs.append(vectors[word])\n",
    "        except:\n",
    "            print(\"{} missing from vocabulary\".format(word))\n",
    "            #continue\n",
    "    return vecs\n",
    "\n",
    "# The function takes as arguments a list of tokenized documents and a window size\n",
    "# and returns each word in the document along with its window context as a tuple\n",
    "\n",
    "def generate_word_counts(documents):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for document in documents:        \n",
    "        for word in set(document):                    \n",
    "            counts[word] += 1\n",
    "            \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declaring the multiple definitions of \"charge\" and \"state\"\n",
    "\n",
    "charge_def = {1:\"(criminal law) a pleading describing some wrong or offense\",\n",
    "              2:\"a quantity of explosive to be set off at one time\",\n",
    "              3:\"the quantity of unbalanced electricity in a body (either positive or negative) and construed as an excess or deficiency of electrons\",\n",
    "              4:\"request for payment of a debt\"}\n",
    "\n",
    "state_def = {1:\"the condition of matter with respect to structure, form, constitution, phase, or the like\",\n",
    "            2:\"a politically unified people occupying a definite territory\",\n",
    "            3: \"express something definitely or clearly in speech or writing\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pretrained word embeddings model\n",
    "\n",
    "model = gensim.models.word2vec.Word2Vec.load(\"../data/journal.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count\n",
    "vectors = model.wv\n",
    "vocab = vectors.vocab\n",
    "word_counts = generate_word_counts(MyPapers_plus(papers))\n",
    "len(vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arguments: List of tokenized word sequence and returns word sequences corresponding to window_size\n",
    "\n",
    "def target_context(sentence, target, window_size = 6):\n",
    "    maxlen = window_size*2\n",
    "    \n",
    "    L = len(sentence)\n",
    "    # Choose the target word\n",
    "    target_arg = sentence.index(target)\n",
    "\n",
    "    s = target_arg-window_size\n",
    "    e = target_arg+window_size+1\n",
    "\n",
    "    context_words = []\n",
    "    # Create the input/outputs for skipgrams\n",
    "    for i in range(s, e):\n",
    "        if 0 <= i < L:\n",
    "            context_words.append(sentence[i])\n",
    "            \n",
    "    return context_words\n",
    "\n",
    "def read_glossary(glossary):\n",
    "    \n",
    "    vector_glossary = dict()\n",
    "    \n",
    "    for k, v in glossary.items():\n",
    "        vector_glossary[k] = {key:vector_average2(tokenize.word_tokenize(value)) for (key,value) in v.items()}\n",
    "    \n",
    "    return vector_glossary\n",
    "\n",
    "def get_target_sentences(documents, target):\n",
    "    \n",
    "    context_sentences = []\n",
    "\n",
    "    for document in documents:\n",
    "        #print(document[:15])\n",
    "        sentence = document\n",
    "        if target in sentence:\n",
    "            #str_sentence = streamlined_sentence(sentence)\n",
    "            #print[str_sentence]\n",
    "            #sentence.remove(target)\n",
    "            context_sentences.append(sentence)\n",
    "            \n",
    "    return context_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a corpus of sentences containing the word state\n",
    "\n",
    "target = ' state '\n",
    "sentences = MySentences('../data/train_data.json')\n",
    "STATE_sentences = get_target_sentences(sentences,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STATE_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_sentences = random.sample(STATE_sentences, 600)\n",
    "sense_label = np.zeros(len(STATE_sentences))\n",
    "sense_label.fill(-1)\n",
    "STATE_df = pd.DataFrame({'sentences':STATE_sentences, 'sense_labels':sense_label})\n",
    "STATE_df.to_pickle('STATE_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle small slices of the previously created dataframe to label through the terminal\n",
    "STATE_df = pd.read_pickle('STATE_df.pkl')\n",
    "\n",
    "start = 0\n",
    "labeled_frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = STATE_df[start:start+20]\n",
    "df.to_pickle('STATE_df.pkl')\n",
    "start+=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_frames.append(pd.read_pickle('STATE_df_labeled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the labeled dataframe slices\n",
    "STATE_df_labeled = pd.concat(labeled_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out indeterminate labels\n",
    "STATE_df_labeled['sense_labels'] = STATE_df_labeled['sense_labels'].apply(lambda x : -1 if x == '' else x )\n",
    "STATE_df_labeled['sense_labels'] = STATE_df_labeled['sense_labels'].apply(lambda x : int(x) )\n",
    "STATE_df_labeled = STATE_df_labeled[STATE_df_labeled['sense_labels'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_plus(line):\n",
    "    line = re.sub(r'[?\\.,!:;\\(\\)“\\[\\]]',' ',line)\n",
    "    line = [word for word in line.lower().split() if word not in stop]\n",
    "    \n",
    "    return line\n",
    "\n",
    "STATE_df_labeled['tokenized_sentences'] = STATE_df_labeled['sentences'].apply(tokenize_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'state'\n",
    "STATE_df_labeled['window'] = STATE_df_labeled['tokenized_sentences'].apply(lambda x : target_context(x, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sense_labels</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2</td>\n",
       "      <td>In this regard  sovereignty is conditional  th...</td>\n",
       "      <td>[regard, sovereignty, conditional, state’s, le...</td>\n",
       "      <td>[humanitarian, intervention, means, military, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2</td>\n",
       "      <td>Breidahl argues that similar  strong and roote...</td>\n",
       "      <td>[breidahl, argues, similar, strong, rooted, no...</td>\n",
       "      <td>[breidahl, argues, similar, strong, rooted, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2</td>\n",
       "      <td>We thus reanalyse the most up-to-date pan-Amaz...</td>\n",
       "      <td>[thus, reanalyse, up-to-date, pan-amazon, data...</td>\n",
       "      <td>[dynamics, decade-by-decade, level, biogeograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2</td>\n",
       "      <td>However  as Chinese firms become more involved...</td>\n",
       "      <td>[however, chinese, firms, become, involved, fo...</td>\n",
       "      <td>[organisations, leading, potential, tension, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2</td>\n",
       "      <td>Despite beginning from very similar innovation...</td>\n",
       "      <td>[despite, beginning, similar, innovation, syst...</td>\n",
       "      <td>[model, transition, economies, noting, importa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sense_labels                                          sentences  \\\n",
       "220             2  In this regard  sovereignty is conditional  th...   \n",
       "221             2  Breidahl argues that similar  strong and roote...   \n",
       "222             2  We thus reanalyse the most up-to-date pan-Amaz...   \n",
       "223             2  However  as Chinese firms become more involved...   \n",
       "224             2  Despite beginning from very similar innovation...   \n",
       "\n",
       "                                   tokenized_sentences  \\\n",
       "220  [regard, sovereignty, conditional, state’s, le...   \n",
       "221  [breidahl, argues, similar, strong, rooted, no...   \n",
       "222  [thus, reanalyse, up-to-date, pan-amazon, data...   \n",
       "223  [however, chinese, firms, become, involved, fo...   \n",
       "224  [despite, beginning, similar, innovation, syst...   \n",
       "\n",
       "                                                window  \n",
       "220  [humanitarian, intervention, means, military, ...  \n",
       "221  [breidahl, argues, similar, strong, rooted, no...  \n",
       "222  [dynamics, decade-by-decade, level, biogeograp...  \n",
       "223  [organisations, leading, potential, tension, d...  \n",
       "224  [model, transition, economies, noting, importa...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATE_df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('STATE_df_labeled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_df_labeled = pd.concat([STATE_df_labeled,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STATE_df_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_df_labeled.to_pickle('STATE_df_labeled.pkl')\n",
    "STATE_df[start:].to_pickle('STATE_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function no longer used\n",
    "\n",
    "def pad_vector_sequence(vector_list, max_len = 12):\n",
    "    array_len = len(vector_list)\n",
    "    if array_len < max_len:\n",
    "        new = list(vector_list) + (max_len-array_len)*[0]\n",
    "        return new\n",
    "    else:\n",
    "        return np.array(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_df_labeled = pd.read_pickle('STATE_df_labeled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a corpus of sentences containing the word state\n",
    "\n",
    "target = ' state '\n",
    "sentences = MySentences('../data/validation_data.json')\n",
    "STATE_sentences = get_target_sentences(sentences,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#STATE_sentences = random.sample(STATE_sentences, 600)\n",
    "sense_label = np.zeros(len(STATE_sentences))\n",
    "sense_label.fill(-1)\n",
    "STATE_val_df = pd.DataFrame({'sentences':STATE_sentences, 'sense_labels':sense_label})\n",
    "STATE_val_df.to_pickle('STATE_val_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STATE_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle small slices of the previously created dataframe to label through the terminal\n",
    "#STATE_val_df = pd.read_pickle('STATE_val_df.pkl')\n",
    "\n",
    "start = 0\n",
    "labeled_val_frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = STATE_val_df[start:start+20]\n",
    "df.to_pickle('STATE_val_df.pkl')\n",
    "start+=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_val_frames.append(pd.read_pickle('STATE_val_df_labeled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_val_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the labeled dataframe slices\n",
    "STATE_val_df_labeled = pd.concat(labeled_val_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out indeterminate labels\n",
    "STATE_val_df_labeled['sense_labels'] = STATE_val_df_labeled['sense_labels'].apply(lambda x : -1 if x == '' else x )\n",
    "STATE_val_df_labeled['sense_labels'] = STATE_val_df_labeled['sense_labels'].apply(lambda x : int(x) )\n",
    "STATE_val_df_labeled = STATE_val_df_labeled[STATE_val_df_labeled['sense_labels'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_plus(line):\n",
    "    line = re.sub(r'[?\\.,!:;\\(\\)“\\[\\]]',' ',line)\n",
    "    line = [word for word in line.lower().split() if word not in stop]\n",
    "    \n",
    "    return line\n",
    "\n",
    "STATE_val_df_labeled['tokenized_sentences'] = STATE_val_df_labeled['sentences'].apply(tokenize_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'state'\n",
    "STATE_val_df_labeled['window'] = STATE_val_df_labeled['tokenized_sentences'].apply(lambda x : target_context(x, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_val_df_labeled.to_pickle('STATE_val_df_labeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATE_df_labeled = pd.read_pickle('STATE_df_labeled.pkl')\n",
    "STATE_val_df_labeled = pd.read_pickle('STATE_val_df_labeled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM classifier for word sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Activation, SimpleRNN, GRU, LSTM, Bidirectional, Convolution1D, MaxPooling1D, Merge, Dropout\n",
    "from IPython.display import SVG\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = keras.utils.to_categorical(STATE_df_labeled['sense_labels'].apply((lambda x: x-1)), num_classes=3)\n",
    "Y_val = keras.utils.to_categorical(STATE_val_df_labeled['sense_labels'].apply((lambda x: x-1)), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_lists(x):\n",
    "    return \" \".join(x)\n",
    "\n",
    "STATE_df_labeled['clean'] = STATE_df_labeled['window'].apply(clean_lists)\n",
    "STATE_val_df_labeled['clean'] = STATE_val_df_labeled['window'].apply(clean_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [ x for x in STATE_df_labeled['clean']]\n",
    "val_corpus = [ x for x in STATE_val_df_labeled['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_filter= '!\\“#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "tokenizer = Tokenizer(filters=my_filter)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "#tokenizer2 = Tokenizer(filters=my_filter)\n",
    "tokenizer.fit_on_texts(val_corpus)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = sequence.pad_sequences(sequences, maxlen=12)\n",
    "val_sequences = sequence.pad_sequences(val_sequences, maxlen=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train, test, split\n",
    "X_train,X_test, y_train,  y_test = sequences, val_sequences, Y, Y_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = len(tokenizer.word_index) + 1\n",
    "nb_epoch = 20\n",
    "\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(Embedding(max_features, output_dim=128))\n",
    "# Bidirectional LSTM!!!\n",
    "LSTM_model.add(Bidirectional(LSTM(128)))\n",
    "LSTM_model.add(Dropout(0.5))\n",
    "LSTM_model.add(Dense(3, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 434 samples, validate on 271 samples\n",
      "Epoch 1/20\n",
      "434/434 [==============================] - 0s - loss: 1.0508 - acc: 0.5184 - val_loss: 0.9568 - val_acc: 0.5240\n",
      "Epoch 2/20\n",
      "434/434 [==============================] - 0s - loss: 0.8639 - acc: 0.5438 - val_loss: 0.9446 - val_acc: 0.5240\n",
      "Epoch 3/20\n",
      "434/434 [==============================] - 0s - loss: 0.7745 - acc: 0.5438 - val_loss: 0.9220 - val_acc: 0.5240\n",
      "Epoch 4/20\n",
      "434/434 [==============================] - 0s - loss: 0.5210 - acc: 0.7442 - val_loss: 1.0738 - val_acc: 0.5314\n",
      "Epoch 5/20\n",
      "434/434 [==============================] - 0s - loss: 0.1614 - acc: 0.9424 - val_loss: 2.0652 - val_acc: 0.4576\n",
      "Epoch 6/20\n",
      "434/434 [==============================] - 0s - loss: 0.0516 - acc: 0.9931 - val_loss: 2.0714 - val_acc: 0.4576\n",
      "Epoch 7/20\n",
      "434/434 [==============================] - 0s - loss: 0.0221 - acc: 1.0000 - val_loss: 2.2717 - val_acc: 0.4871\n",
      "Epoch 8/20\n",
      "434/434 [==============================] - 0s - loss: 0.0099 - acc: 1.0000 - val_loss: 2.3585 - val_acc: 0.4797\n",
      "Epoch 9/20\n",
      "434/434 [==============================] - 0s - loss: 0.0045 - acc: 1.0000 - val_loss: 2.1868 - val_acc: 0.4797\n",
      "Epoch 10/20\n",
      "434/434 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 2.3459 - val_acc: 0.4871\n",
      "Epoch 11/20\n",
      "434/434 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 2.4033 - val_acc: 0.4871\n",
      "Epoch 12/20\n",
      "434/434 [==============================] - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 2.4551 - val_acc: 0.4908\n",
      "Epoch 13/20\n",
      "434/434 [==============================] - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 2.5432 - val_acc: 0.4945\n",
      "Epoch 14/20\n",
      "434/434 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 2.5127 - val_acc: 0.4686\n",
      "Epoch 15/20\n",
      "434/434 [==============================] - 0s - loss: 9.0010e-04 - acc: 1.0000 - val_loss: 2.6655 - val_acc: 0.4797\n",
      "Epoch 16/20\n",
      "434/434 [==============================] - 0s - loss: 7.7040e-04 - acc: 1.0000 - val_loss: 2.6770 - val_acc: 0.4871\n",
      "Epoch 17/20\n",
      "434/434 [==============================] - 0s - loss: 6.9019e-04 - acc: 1.0000 - val_loss: 2.7482 - val_acc: 0.4908\n",
      "Epoch 18/20\n",
      "434/434 [==============================] - 0s - loss: 7.3768e-04 - acc: 1.0000 - val_loss: 2.8185 - val_acc: 0.4871\n",
      "Epoch 19/20\n",
      "434/434 [==============================] - 0s - loss: 6.6656e-04 - acc: 1.0000 - val_loss: 2.7730 - val_acc: 0.4760\n",
      "Epoch 20/20\n",
      "434/434 [==============================] - 0s - loss: 4.5650e-04 - acc: 1.0000 - val_loss: 2.8479 - val_acc: 0.4871\n"
     ]
    }
   ],
   "source": [
    "LSTM_model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "history = LSTM_model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data = [X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96163911881042141, 0.92136411385342643, 0.93627227892295017, 1.1494698581660365, 1.9204266660767728, 2.3904732593311153, 2.6893451468970944, 2.4579624909756368, 3.4392032077831534, 2.1637966254540477, 2.1584397066123371, 2.3695225786019076, 2.5054884563952795, 2.5872767015576801, 2.6410739386653548, 2.68239881103769, 2.7194641533812915, 2.7661568080367198, 2.7999256017903122, 2.8300447032900315]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_history = []\n",
    "accuracy_history.append(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 434 samples, validate on 271 samples\n",
      "Epoch 1/20\n",
      "434/434 [==============================] - 0s - loss: 9.8255e-04 - acc: 1.0000 - val_loss: 3.1283 - val_acc: 0.4244\n",
      "Epoch 2/20\n",
      "434/434 [==============================] - 0s - loss: 3.8422e-04 - acc: 1.0000 - val_loss: 3.1233 - val_acc: 0.4207\n",
      "Epoch 3/20\n",
      "434/434 [==============================] - 0s - loss: 1.6277e-04 - acc: 1.0000 - val_loss: 3.3384 - val_acc: 0.4207\n",
      "Epoch 4/20\n",
      "434/434 [==============================] - 0s - loss: 9.8870e-05 - acc: 1.0000 - val_loss: 3.7294 - val_acc: 0.4096\n",
      "Epoch 5/20\n",
      "434/434 [==============================] - 0s - loss: 4.1781e-05 - acc: 1.0000 - val_loss: 3.8763 - val_acc: 0.4022\n",
      "Epoch 6/20\n",
      "434/434 [==============================] - 0s - loss: 5.7276e-05 - acc: 1.0000 - val_loss: 4.1570 - val_acc: 0.3985\n",
      "Epoch 7/20\n",
      "434/434 [==============================] - 0s - loss: 1.5411e-05 - acc: 1.0000 - val_loss: 4.2568 - val_acc: 0.3948\n",
      "Epoch 8/20\n",
      "434/434 [==============================] - 0s - loss: 1.0827e-05 - acc: 1.0000 - val_loss: 4.1818 - val_acc: 0.3801\n",
      "Epoch 9/20\n",
      "434/434 [==============================] - 0s - loss: 0.0248 - acc: 0.9862 - val_loss: 3.6296 - val_acc: 0.5092\n",
      "Epoch 10/20\n",
      "434/434 [==============================] - 0s - loss: 0.0218 - acc: 0.9977 - val_loss: 2.2421 - val_acc: 0.5055\n",
      "Epoch 11/20\n",
      "434/434 [==============================] - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 2.8919 - val_acc: 0.5018\n",
      "Epoch 12/20\n",
      "434/434 [==============================] - 0s - loss: 1.6771e-04 - acc: 1.0000 - val_loss: 3.1983 - val_acc: 0.5240\n",
      "Epoch 13/20\n",
      "434/434 [==============================] - 0s - loss: 1.4747e-04 - acc: 1.0000 - val_loss: 3.4240 - val_acc: 0.5129\n",
      "Epoch 14/20\n",
      "434/434 [==============================] - 0s - loss: 1.0089e-04 - acc: 1.0000 - val_loss: 3.4929 - val_acc: 0.5166\n",
      "Epoch 15/20\n",
      "434/434 [==============================] - 0s - loss: 1.0318e-04 - acc: 1.0000 - val_loss: 3.5377 - val_acc: 0.5240\n",
      "Epoch 16/20\n",
      "434/434 [==============================] - 0s - loss: 6.0562e-05 - acc: 1.0000 - val_loss: 3.5615 - val_acc: 0.5203\n",
      "Epoch 17/20\n",
      "434/434 [==============================] - 0s - loss: 7.1321e-05 - acc: 1.0000 - val_loss: 3.5791 - val_acc: 0.5203\n",
      "Epoch 18/20\n",
      "434/434 [==============================] - 0s - loss: 5.4352e-05 - acc: 1.0000 - val_loss: 3.6010 - val_acc: 0.5203\n",
      "Epoch 19/20\n",
      "434/434 [==============================] - 0s - loss: 6.5067e-05 - acc: 1.0000 - val_loss: 3.6257 - val_acc: 0.5166\n",
      "Epoch 20/20\n",
      "434/434 [==============================] - 0s - loss: 6.2543e-05 - acc: 1.0000 - val_loss: 3.6466 - val_acc: 0.5092\n"
     ]
    }
   ],
   "source": [
    "LSTM_model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "history = LSTM_model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data = [X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_history.append(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 434 samples, validate on 271 samples\n",
      "Epoch 1/20\n",
      "434/434 [==============================] - 0s - loss: 1.3217e-05 - acc: 1.0000 - val_loss: 4.6100 - val_acc: 0.5018\n",
      "Epoch 2/20\n",
      "434/434 [==============================] - 0s - loss: 2.1884e-06 - acc: 1.0000 - val_loss: 5.4533 - val_acc: 0.5277\n",
      "Epoch 3/20\n",
      "434/434 [==============================] - 0s - loss: 8.6153e-07 - acc: 1.0000 - val_loss: 5.6848 - val_acc: 0.5240\n",
      "Epoch 4/20\n",
      "434/434 [==============================] - 0s - loss: 1.1941e-06 - acc: 1.0000 - val_loss: 5.6078 - val_acc: 0.5055cc: 1\n",
      "Epoch 5/20\n",
      "434/434 [==============================] - 0s - loss: 6.7996e-07 - acc: 1.0000 - val_loss: 5.6196 - val_acc: 0.4945\n",
      "Epoch 6/20\n",
      "434/434 [==============================] - 0s - loss: 4.6365e-07 - acc: 1.0000 - val_loss: 5.7448 - val_acc: 0.5129\n",
      "Epoch 7/20\n",
      "434/434 [==============================] - 0s - loss: 5.1365e-07 - acc: 1.0000 - val_loss: 5.7792 - val_acc: 0.5129\n",
      "Epoch 8/20\n",
      "434/434 [==============================] - 0s - loss: 3.3552e-07 - acc: 1.0000 - val_loss: 5.7487 - val_acc: 0.5129\n",
      "Epoch 9/20\n",
      "434/434 [==============================] - 0s - loss: 3.4032e-07 - acc: 1.0000 - val_loss: 5.7526 - val_acc: 0.5129\n",
      "Epoch 10/20\n",
      "434/434 [==============================] - 0s - loss: 2.5174e-07 - acc: 1.0000 - val_loss: 5.7717 - val_acc: 0.5129\n",
      "Epoch 11/20\n",
      "434/434 [==============================] - 0s - loss: 2.8992e-07 - acc: 1.0000 - val_loss: 5.8675 - val_acc: 0.5129\n",
      "Epoch 12/20\n",
      "434/434 [==============================] - 0s - loss: 2.4941e-07 - acc: 1.0000 - val_loss: 5.8775 - val_acc: 0.5092cc: 1.\n",
      "Epoch 13/20\n",
      "434/434 [==============================] - 0s - loss: 2.8209e-07 - acc: 1.0000 - val_loss: 5.8298 - val_acc: 0.5129\n",
      "Epoch 14/20\n",
      "434/434 [==============================] - 0s - loss: 2.3032e-07 - acc: 1.0000 - val_loss: 5.8312 - val_acc: 0.5129\n",
      "Epoch 15/20\n",
      "434/434 [==============================] - 0s - loss: 2.1246e-07 - acc: 1.0000 - val_loss: 5.8175 - val_acc: 0.5129\n",
      "Epoch 16/20\n",
      "434/434 [==============================] - 0s - loss: 2.1054e-07 - acc: 1.0000 - val_loss: 5.8181 - val_acc: 0.5129\n",
      "Epoch 17/20\n",
      "434/434 [==============================] - 0s - loss: 2.0724e-07 - acc: 1.0000 - val_loss: 5.8401 - val_acc: 0.5129\n",
      "Epoch 18/20\n",
      "434/434 [==============================] - 0s - loss: 1.6645e-07 - acc: 1.0000 - val_loss: 5.8711 - val_acc: 0.5129\n",
      "Epoch 19/20\n",
      "434/434 [==============================] - 0s - loss: 2.3705e-07 - acc: 1.0000 - val_loss: 5.8617 - val_acc: 0.5129\n",
      "Epoch 20/20\n",
      "434/434 [==============================] - 0s - loss: 1.8101e-07 - acc: 1.0000 - val_loss: 5.8633 - val_acc: 0.5129\n"
     ]
    }
   ],
   "source": [
    "LSTM_model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "history = LSTM_model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data = [X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_history.append(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.79900700e-02,   1.62087765e-03,   6.75133342e-05]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.predict(val_sequences[0:1], batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01628c38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(0,len(accuracy_history))\n",
    "ax = plt.plot(x,accuracy_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
